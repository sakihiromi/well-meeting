# Well-Meeting

会議の音声をリアルタイムで分析し、複数の指標（威圧度、逸脱度、発言無効度、偏り度）でスコアリングするシステムです。OpenAI Whisper API（gpt-4o-mini-transcribe）による音声認識とLLMカットによる高度なスコアリング技術を使用しています。

## 目次

- [クイックスタート](#クイックスタート) - **初めて使う方はこちらから**
- [概要](#概要)
- [主な機能](#主な機能)
- [システムアーキテクチャ](#システムアーキテクチャ)
- [セットアップ](#セットアップ)
- [使用方法](#使用方法)
- [環境変数の詳細](#環境変数の詳細)
- [APIエンドポイント](#apiエンドポイント)
- [指標の詳細](#指標の詳細)
- [ファイル構成](#ファイル構成)
- [トラブルシューティング](#トラブルシューティング)
- [開発者向け情報](#開発者向け情報)

## クイックスタート

このセクションでは、Well-Meetingを初めて使う方向けに、システムを動かすための**完全な手順**を説明します。

### このシステムを動かすには

Well-Meetingは**3つのサーバー**を同時に起動する必要があります。それぞれ別のターミナルで起動してください。

#### ステップ1: 環境の準備

1. **conda環境をアクティベート**
```bash
conda activate teams2wb
```

2. **プロジェクトディレクトリに移動**
```bash
cd /Users/saki/lab/US/well-meeting
```

3. **依存パッケージのインストール確認**
```bash
pip install -r requirements.txt
```

4. **環境変数ファイル（.env）の確認・作成**

プロジェクトディレクトリに`.env`ファイルがあることを確認してください。なければ以下の内容で作成します：

```env
# ポート設定
CONTROL_PORT=50000
MIC_PORT=50001
API_PORT=8008
API_IP=localhost
DASH_PORT=8050
DASH_IP=localhost

# OpenAI API（必須：実際のAPIキーを設定してください）
OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL_NAME=gpt-4o-2024-08-06
OPENAI_ENDPOINT=
OPENAI_API_VERSION=2024-08-01-preview

# 会議設定
MEETING_TYPE=定例・進捗
MEETING_GOAL=システムの動作確認
USER_NAME=名称未設定
EVAL_LINES=10

# 指標設定
EXTRA_JSON_FILE=extra.json
SELECTED_METRICS=威圧度,逸脱度,発言無効度,偏り度
```

**重要**: `OPENAI_API_KEY`には実際のOpenAI APIキーを設定してください。APIキーがないとシステムは動作しません。

#### ステップ2: サーバー1 - control.pyを起動

**ターミナル1**を開き、以下を実行：

```bash
conda activate teams2wb
cd /Users/saki/lab/US/well-meeting
python control.py
```

**正常な起動時の出力例**:
```
初期化パラメータ:
  control_port: 50000
  api_port: 8008
  selected_metrics: ['威圧度', '逸脱度', '発言無効度', '偏り度']
[MainNode] TCPサーバを起動します: 0.0.0.0:50000
[MainNode] LISTEN中: 0.0.0.0:50000
INFO:     Started server process [xxxxx]
INFO:     Uvicorn running on http://0.0.0.0:8008 (Press CTRL+C to quit)
```

このターミナルは**開いたまま**にしてください（Ctrl+Cで停止）。

#### ステップ3: サーバー2 - mic_api.pyを起動

**ターミナル2**を開き（新しいターミナルウィンドウ）、以下を実行：

```bash
conda activate teams2wb
cd /Users/saki/lab/US/well-meeting
python mic_api.py
```

**正常な起動時の出力例**:
```
[mic] control server listening on 50001
🎙️ Listening ...
```

このターミナルも**開いたまま**にしてください。マイクからの音声を待機しています。

**注意**: 
- 初回起動時、macOSではマイクへのアクセス許可を求められる場合があります。「許可」を選択してください。
- マイクが検出されない場合は、システムのマイク設定を確認してください。

#### ステップ4: サーバー3 - dash_server.pyを起動

**ターミナル3**を開き（さらに新しいターミナルウィンドウ）、以下を実行：

```bash
conda activate teams2wb
cd /Users/saki/lab/US/well-meeting
python dash_server.py
```

**正常な起動時の出力例**:
```
API_BASE: http://localhost:8008
Dash is running on http://localhost:8050/

 * Serving Flask app 'dash_server'
 * Debug mode: off
```

このターミナルも**開いたまま**にしてください。

#### ステップ5: ブラウザでダッシュボードを開く

ブラウザを開き、以下のURLにアクセス：

```
http://localhost:8050
```

**初期設定画面**が表示されます。会議を開始する前に、以下の設定を行ってください：

1. **会議の目的**をテキストエリアに入力
   - 例：「新製品のアイデアを出し合い、実現可能性の高い案を3つに絞り込む」
2. **会議の形式**をチェックボックスから選択（複数選択可）
   - 発散（ブレインストーミング）
   - 収束（アイデアの絞り込み）
   - アイスブレイク（関係構築）
   - 意思決定
   - 振り返り（評価・フィードバック）
   - 情報共有
   - 問題解決
   - 合意形成
   - 定例会議
   - 臨時会議
   - 上長説明
   - 目標設定
3. 「**スタート**」ボタンをクリック

設定完了後、メインダッシュボードが表示されます：
- 上部に会議設定情報と「設定を変更」ボタンが表示されます
- 中央に発言データのテーブルが表示されます（まだデータがない場合は空）
- 下部に指標のグラフが表示されます

#### ステップ6: 実際に使ってみる

1. **マイクに向かって話す**
   - マイクに向かって何か話してください（例：「こんにちは、今日は良い天気ですね」）
   - 最低0.8秒以上話す必要があります

2. **動作確認**
   - **ターミナル2（mic_api.py）**: 「speaking:True」と表示され、その後文字起こし結果が表示されます
   - **ターミナル1（control.py）**: 「処理完了: [発言内容]...」と表示され、評価が開始されます
   - **ブラウザ（ダッシュボード）**: 5秒以内に自動更新され、発言とスコアが表示されます

3. **結果の確認**
   - テーブルに発言内容、タイムスタンプ、各指標のスコアと確信度が表示されます
   - グラフに各指標の推移が表示されます（色分け：緑=低、黄=中、赤=高）

#### ステップ7: システムの停止

すべてのサーバーを停止するには、各ターミナルで **Ctrl+C** を押してください。

停止順序は任意ですが、推奨順序：
1. ターミナル3（dash_server.py）
2. ターミナル2（mic_api.py）
3. ターミナル1（control.py）

### 動作の流れ（全体像）

```
1. ユーザーがマイクに向かって話す
   ↓
2. mic_api.pyが音声を検出（VAD）
   ↓
3. OpenAI Whisper APIで文字起こし
   ↓
4. control.pyへTCP通信でテキスト送信
   ↓
5. control.pyがLLMカットで各指標を評価
   ↓
6. 結果をCSVファイルに保存
   ↓
7. dash_server.pyがFastAPIからデータを取得
   ↓
8. ダッシュボードに表示（5秒間隔で自動更新）
```

### 初めて使う際のチェックリスト

起動前に以下を確認してください：

- [ ] conda環境（teams2wb）がインストールされている
- [ ] 依存パッケージがインストールされている（`pip install -r requirements.txt`）
- [ ] `.env`ファイルが存在し、`OPENAI_API_KEY`が設定されている
- [ ] ポート50000, 50001, 8008, 8050が使用可能（他のプロセスが使用していない）
- [ ] マイクが接続され、システムのマイク権限が許可されている
- [ ] 3つのターミナルを開く準備ができている

### よくある質問（初めて使う方向け）

**Q: 3つのターミナルを同時に開く必要がありますか？**
A: はい。3つのサーバーは独立して動作するため、それぞれ別のターミナルで起動する必要があります。

**Q: 起動順序は重要ですか？**
A: 推奨順序は `control.py` → `mic_api.py` → `dash_server.py` です。`control.py`を最初に起動することで、他のサーバーが接続できるようになります。

**Q: マイクが検出されません**
A: システムのマイク権限を確認してください（macOS: システム環境設定 > セキュリティとプライバシー > マイク）。また、マイクが正しく接続されているか確認してください。

**Q: ダッシュボードにデータが表示されません**
A: 以下を確認してください：
1. 3つのサーバーがすべて起動しているか
2. マイクに向かって0.8秒以上話しているか
3. ブラウザのコンソールにエラーがないか
4. `http://localhost:8008/health` にアクセスしてAPIが応答するか

**Q: エラーが発生しました**
A: [トラブルシューティング](#トラブルシューティング)セクションを参照してください。

## 概要

Well-Meetingは、会議中の発言をリアルタイムで分析し、以下の4つの指標で評価するシステムです：

- **威圧度**: 発言の威圧性を評価
- **逸脱度**: 会議の目的からの逸脱度合いを評価
- **発言無効度**: 発言が目的達成にどれだけ寄与していないかを評価
- **偏り度**: 討議の手続的公正に対する偏りを評価

各指標は1-9のスコアと確信度（0-1）で評価され、リアルタイムでダッシュボードに表示されます。

## 主な機能

### 1. リアルタイム音声認識
- **VAD（Voice Activity Detection）**: WebRTC VADを使用した高精度な音声検出（感度0-3調整可能）
- **OpenAI Whisper API**: `gpt-4o-mini-transcribe` モデルによる高精度な日本語音声認識
- **誤作動防止**: 短すぎる音声（0.8秒未満）、空のテキスト、2文字未満のテキストを自動でスキップ
- **自己一致フィルタ**: スピーカーからのエコーを防止
- **バンドパスフィルタ**: 200Hz〜4000Hzの音声帯域を抽出してノイズを低減

### 2. LLMカットによるスコアリング
- **確信度付きスコアリング**: 各指標に対してスコアと確信度を同時に取得
- **並列評価**: 複数の指標を並列で評価し、高速処理を実現
- **文脈考慮**: 過去の発言履歴を考慮した評価

### 3. リアルタイム可視化
- **ダッシュボード**: Plotlyを使用したインタラクティブなグラフ
- **自動更新**: 5秒間隔で自動的にデータを更新
- **指標選択**: 表示する指標を動的に選択可能
- **ゾーン表示**: スコアに応じた色分け表示（緑/黄/赤）
- **総合スコア**: 各指標の平均値を総合スコアとして自動計算・表示

### 4. リアルタイム設定変更
- **設定変更モーダル**: ダッシュボードから会議設定をリアルタイムで変更可能
- **会議形式の選択**: 12種類の会議形式から選択可能（複数選択可）
  - 発散（ブレインストーミング）
  - 収束（アイデアの絞り込み）
  - アイスブレイク（関係構築）
  - 意思決定
  - 振り返り（評価・フィードバック）
  - 情報共有
  - 問題解決
  - 合意形成
  - 定例会議
  - 臨時会議
  - 上長説明
  - 目標設定
- **会議目的の設定**: 自由記述で会議の目的を入力可能
- **即時反映**: 設定変更は即座にスコアリングに反映

### 5. データ管理
- **CSV保存**: すべての発言とスコアをCSV形式で保存
- **ログ管理**: 音声ファイルとテキストログを自動保存
- **履歴管理**: 過去の発言履歴を保持し、文脈評価に活用

## システムアーキテクチャ

```
┌─────────────┐
│  mic_api.py │ 音声入力・文字起こし
│  (ポート50001) │
└──────┬──────┘
       │ TCP通信
       ▼
┌─────────────┐
│ control.py  │ コントロールサーバ
│ (ポート50000)│ - LLMカット評価
│             │ - データ管理
│             │ - FastAPI (ポート8008)
└──────┬──────┘
       │ HTTP API
       ▼
┌─────────────┐
│dash_server.py│ 可視化サーバ
│ (ポート8050) │ - Dash/Plotly
│             │ - リアルタイム表示
└─────────────┘
```

### コンポーネント説明

1. **mic_api.py**: 
   - マイクから音声を取得
   - VADで音声の切れ目を検出
   - OpenAI Whisper APIで文字起こし
   - control.pyへTCP通信でテキストを送信

2. **control.py**:
   - mic_api.pyからのテキストを受信
   - LLMカットを使用して各指標を評価
   - 結果をCSVファイルに保存
   - FastAPIでデータを提供

3. **dash_server.py**:
   - control.pyのFastAPIからデータを取得
   - Plotlyでグラフとテーブルを生成
   - 5秒間隔で自動更新

## セットアップ

### 前提条件

- Python 3.12以上
- conda環境（推奨: `teams2wb`）
- OpenAI APIキー
- マイクデバイス（音声入力用）

### 1. リポジトリのクローン/ダウンロード

```bash
cd /path/to/your/workspace
# プロジェクトディレクトリに移動
cd US/well-meeting
```

### 2. conda環境のアクティベート

```bash
conda activate teams2wb
```

### 3. 依存関係のインストール

```bash
pip install -r requirements.txt
```

主要な依存パッケージ:
- `openai`: OpenAI APIクライアント
- `fastapi`, `uvicorn`: APIサーバー
- `dash`, `plotly`: 可視化
- `sounddevice`, `webrtcvad`: 音声処理
- `pandas`: データ管理
- `python-dotenv`: 環境変数管理

### 4. 環境変数の設定

プロジェクトルートに`.env`ファイルを作成し、以下の内容を設定します：

```env
# ポート設定
CONTROL_PORT=50000
MIC_PORT=50001
API_PORT=8008
API_IP=localhost
DASH_PORT=8050
DASH_IP=localhost

# OpenAI API
OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL_NAME=gpt-4o-2024-08-06
OPENAI_ENDPOINT=  # Azure使用時のみ
OPENAI_API_VERSION=2024-08-01-preview

# 会議設定
MEETING_TYPE=定例・進捗
MEETING_GOAL=システムの動作確認
USER_NAME=名称未設定
EVAL_LINES=10

# 指標設定
EXTRA_JSON_FILE=extra.json
SELECTED_METRICS=威圧度,逸脱度,発言無効度,偏り度  # 空欄なら全指標
```

**重要**: `OPENAI_API_KEY`には実際のAPIキーを設定してください。

### 5. ポートの確認

起動前に、使用するポートが空いていることを確認します：

```bash
# macOS/Linux
lsof -i:50000,50001,8008,8050

# ポートが使用中の場合は、プロセスを停止するか、.envでポート番号を変更してください
```

## 使用方法

### 基本的な使い方

詳細な起動手順は[クイックスタート](#クイックスタート)セクションを参照してください。ここでは、システムを起動した後の使い方を説明します。

### ダッシュボードの使い方

#### 1. ダッシュボードの構成

ブラウザで `http://localhost:8050` にアクセスすると表示されます。

**初回アクセス時（初期設定画面）**:
```
┌─────────────────────────────────────────┐
│ 🎯 Meeting Keeper                        │
│ 会議を開始する前に、以下の設定を行ってください │
├─────────────────────────────────────────┤
│ 会議の目的:                              │
│ [テキストエリア]                         │
├─────────────────────────────────────────┤
│ 会議の形式（複数選択可）:                 │
│ ☐ 発散（ブレインストーミング）            │
│ ☐ 収束（アイデアの絞り込み）              │
│ ☐ アイスブレイク（関係構築）              │
│ ☐ 意思決定 / ☐ 振り返り / ☐ 情報共有     │
│ ☐ 問題解決 / ☐ 合意形成 / ☐ 定例会議     │
│ ☐ 臨時会議 / ☐ 上長説明 / ☐ 目標設定     │
├─────────────────────────────────────────┤
│            [スタート]                    │
└─────────────────────────────────────────┘
```

**設定完了後（メインダッシュボード）**:
```
┌─────────────────────────────────────────┐
│ Meeting Keeper - Dashboard               │
├─────────────────────────────────────────┤
│ 現在の設定                               │
│ - 会議の形式: ○○○                        │
│ - 会議の目的: ○○○                        │
│ [設定を変更] ボタン                       │
├─────────────────────────────────────────┤
│ [指標選択ドロップダウン]                  │
├─────────────────────────────────────────┤
│ 発言データテーブル                        │
│ - timestamp, user, title, score, text   │
│ - 各指標のスコアと確信度                  │
├─────────────────────────────────────────┤
│ 指標グラフ（選択した指標が表示される）     │
│ - 総合スコア（平均）の推移グラフ          │
│ - 威圧度の推移グラフ                      │
│ - 逸脱度の推移グラフ                      │
│ - 発言無効度の推移グラフ                  │
│ - 偏り度の推移グラフ                      │
└─────────────────────────────────────────┘
```

#### 2. 会議設定の変更

ダッシュボード上部の「設定を変更」ボタンから、会議中でもリアルタイムで設定を変更できます：

1. 「設定を変更」ボタンをクリック
2. モーダルダイアログが表示されます
3. **会議の形式**をチェックボックスから選択（複数選択可）：
   - 発散（ブレインストーミング）
   - 収束（アイデアの絞り込み）
   - アイスブレイク（関係構築）
   - 意思決定
   - 振り返り（評価・フィードバック）
   - 情報共有
   - 問題解決
   - 合意形成
   - 定例会議
   - 臨時会議
   - 上長説明
   - 目標設定
4. **会議の目的**をテキストエリアに入力
5. 「保存」をクリックして設定を反映

設定変更は即座にスコアリングに反映され、以降の発言は新しい設定に基づいて評価されます。

#### 3. 指標の選択

- 上部の「表示する指標を選択してください」ドロップダウンから、表示したい指標を選択できます
- 複数選択可能です
- 何も選択しない場合は、すべての指標が表示されます
- 「総合」を選択すると、総合スコア（各指標の平均）のグラフが表示されます

#### 4. グラフの見方

各指標のグラフには以下の情報が表示されます：

- **X軸**: 時間（タイムスタンプ）
- **Y軸**: スコア（1-9）
- **色分け**:
  - 🟢 緑: 低スコア（1-3）- 通常ゾーン
  - 🟡 黄: 中スコア（4-6）- 注意ゾーン
  - 🔴 赤: 高スコア（7-9）- 警戒ゾーン

**総合スコア**について：
- 総合スコアは各指標（威圧度、逸脱度、発言無効度、偏り度）の平均値として自動計算されます
- すべての指標の評価が完了すると「総合(平均)」として表示されます

#### 5. テーブルの見方

テーブルには以下の情報が表示されます：

- **timestamp**: 発言の時刻
- **user**: 発言者の名前
- **text**: 発言内容
- **score(総合)**: 総合スコア（現在は未使用）
- **conf(総合)**: 総合確信度（現在は未使用）
- **各指標のスコア**: 威圧度スコア、逸脱度スコアなど
- **各指標の確信度**: 威圧度確信度、逸脱度確信度など
- **metrics(JSON)**: すべての指標データのJSON形式

#### 6. 自動更新

- ダッシュボードは**5秒間隔**で自動的に更新されます
- 新しい発言が追加されると、自動的にテーブルとグラフに反映されます
- 手動で更新する必要はありません

### 会議中の使い方

#### 1. 会議開始前の準備

1. 3つのサーバーを起動（[クイックスタート](#クイックスタート)参照）
2. ダッシュボードを開く
3. マイクの位置と音量を確認
4. `.env`ファイルで会議設定を確認・変更：
   - `MEETING_TYPE`: 会議の形式
   - `MEETING_GOAL`: 会議の目的
   - `USER_NAME`: ユーザー名（空の場合は自動設定）

#### 2. 会議中の動作

1. **自然に話す**: マイクに向かって通常通り話してください
   - 最低0.8秒以上話す必要があります
   - 短すぎる発言は自動的にスキップされます

2. **音声検出の確認**: 
   - `mic_api.py`のターミナルに「speaking:True」と表示されれば、音声が検出されています
   - 表示されない場合は、マイクの音量や位置を確認してください

3. **評価結果の確認**:
   - 発言後、数秒でダッシュボードに結果が表示されます
   - 各指標のスコアと確信度を確認できます
   - 総合スコア（各指標の平均）も自動計算されます
   - グラフで時系列の推移を確認できます

4. **リアルタイム設定変更**:
   - 会議の途中で形式や目的が変わった場合、ダッシュボードから即座に設定を変更できます
   - 「設定を変更」ボタンから新しい会議形式・目的を設定すると、以降の発言は新しい設定で評価されます

#### 3. 会議終了後

1. **データの保存確認**:
   - `meeting_keeper.csv`にすべての発言とスコアが保存されています
   - `log/`ディレクトリに音声ファイルとテキストログが保存されています

2. **サーバーの停止**:
   - 各ターミナルでCtrl+Cを押してサーバーを停止
   - データは既に保存されているため、安全に停止できます

### カスタム環境変数ファイルの使用

異なる設定で複数の会議を管理する場合、カスタム環境変数ファイルを使用できます：

```bash
# 会議A用の設定
python control.py --file .env.meeting_a
python mic_api.py --file .env.meeting_a
python dash_server.py --file .env.meeting_a

# 会議B用の設定
python control.py --file .env.meeting_b
python mic_api.py --file .env.meeting_b
python dash_server.py --file .env.meeting_b
```

### データの確認方法

#### CSVファイルの確認

```bash
# 発言データとスコアを確認
cat meeting_keeper.csv

# またはExcelやスプレッドシートで開く
open meeting_keeper.csv  # macOS
```

#### ログファイルの確認

```bash
# 文字起こしログを確認
ls -la log/mic_text_*.txt
cat log/mic_text_*.txt

# 音声ファイルを確認（WAV形式）
ls -la log/*.wav
```

### 高度な使い方

#### 指標のカスタマイズ

`extra.json`を編集することで、評価する指標をカスタマイズできます：

1. `extra.json`を開く
2. 新しい指標を追加、または既存の指標を編集
3. `.env`の`SELECTED_METRICS`に追加（または空欄で全指標を使用）
4. サーバーを再起動

詳細は[指標の詳細](#指標の詳細)セクションを参照してください。

#### 評価行数の調整

過去の発言をどれだけ考慮するかは、`.env`の`EVAL_LINES`で調整できます：

- デフォルト: `10`（過去10発言を考慮）
- より多くの文脈を考慮する場合: `20`などに増やす
- より少ない文脈で評価する場合: `5`などに減らす

#### リアルタイム監視

会議中にリアルタイムでスコアを監視する場合：

1. ダッシュボードを開いたままにする
2. 指標選択で監視したい指標を選択
3. グラフの色分けで問題のある発言を素早く識別
4. テーブルで詳細なスコアを確認

### 動作確認のチェックリスト

システムが正常に動作しているか確認するためのチェックリスト：

- [ ] 3つのサーバーがすべて起動している
- [ ] ダッシュボードが `http://localhost:8050` で表示される
- [ ] マイクに向かって話すと、`mic_api.py`のターミナルに「speaking:True」が表示される
- [ ] 文字起こし結果が`mic_api.py`のターミナルに表示される
- [ ] `control.py`のターミナルに「処理完了」が表示される
- [ ] ダッシュボードに発言とスコアが表示される（5秒以内）
- [ ] `meeting_keeper.csv`にデータが保存されている
- [ ] `log/`ディレクトリに音声ファイルとログが保存されている

## 環境変数の詳細

### ポート設定

| 変数名 | デフォルト値 | 説明 |
|--------|------------|------|
| `CONTROL_PORT` | 50000 | control.pyのTCPサーバーポート |
| `MIC_PORT` | 50001 | mic_api.pyの制御サーバーポート |
| `API_PORT` | 8008 | FastAPIサーバーのポート |
| `API_IP` | localhost | FastAPIサーバーのIPアドレス |
| `DASH_PORT` | 8050 | Dashサーバーのポート |
| `DASH_IP` | localhost | DashサーバーのIPアドレス |

### OpenAI API設定

| 変数名 | デフォルト値 | 説明 |
|--------|------------|------|
| `OPENAI_API_KEY` | (必須) | OpenAI APIキー |
| `OPENAI_MODEL_NAME` | gpt-4o-2024-08-06 | 使用するモデル名 |
| `OPENAI_ENDPOINT` | (空) | Azure OpenAI使用時のエンドポイント |
| `OPENAI_API_VERSION` | 2024-08-01-preview | APIバージョン（Azure使用時） |

### 会議設定

| 変数名 | デフォルト値 | 説明 |
|--------|------------|------|
| `MEETING_TYPE` | (空) | 会議の形式（例: 定例・進捗） |
| `MEETING_GOAL` | (空) | 会議の目的 |
| `USER_NAME` | (空) | ユーザー名（空の場合はmic_api.pyから送信された値を使用） |
| `EVAL_LINES` | 10 | 評価時に考慮する過去の発言行数 |

### 指標設定

| 変数名 | デフォルト値 | 説明 |
|--------|------------|------|
| `EXTRA_JSON_FILE` | extra.json | 指標定義ファイルのパス |
| `SELECTED_METRICS` | (空) | 評価する指標（カンマ区切り）。空の場合は全指標を評価 |

## APIエンドポイント

control.pyが提供するFastAPIエンドポイント：

### GET /health
サーバーの稼働状況を確認

**レスポンス**:
```json
{
  "status": "ok"
}
```

### GET /params
現在の設定パラメータを取得（APIキーは除外）

**レスポンス**:
```json
{
  "params": {
    "control_port": 50000,
    "api_port": 8008,
    "meeting_type": "定例・進捗",
    "meeting_goal": "システムの動作確認",
    ...
  }
}
```

### GET /data
すべての発言データとスコアを取得

**レスポンス**:
```json
{
  "rows": [
    {
      "user": "ユーザー名",
      "text": "発言内容",
      "timestamp": "2024-01-01T12:00:00",
      "title": "総合(平均)",
      "score": 4,
      "conf": 0.82,
      "威圧度スコア": 3,
      "威圧度確信度": 0.85,
      "metrics": [
        {
          "指標": "威圧度",
          "スコア": 3,
          "確信度": 0.85
        },
        ...
      ]
    },
    ...
  ]
}
```

### POST /update_settings
会議設定をリアルタイムで更新

**リクエストボディ**:
```json
{
  "meeting_type": "発散",
  "meeting_goal": "新機能のアイデア出し"
}
```

**レスポンス（成功時）**:
```json
{
  "status": "success",
  "message": "会議の設定を更新しました（形式: 発散, 目的: 新機能のアイデア出し）"
}
```

**レスポンス（失敗時）**:
```json
{
  "status": "error",
  "message": "更新に失敗しました: エラーメッセージ"
}
```

## 指標の詳細

### 威圧度

**定義**: 発言の威圧性（言葉の強さ・強要・皮肉・相手に与える心理的プレッシャー）を評価する。

**スコア基準**:
- **低(1-3)**: 敬意・配慮があり威圧的でない
- **中(4-6)**: やや強め・配慮不足が一部見られる
- **高(7-9)**: 強要・侮蔑・恫喝など過度な圧力

**評価時の質問**: この発言は不当な圧力や威圧感を与えていないか？

### 逸脱度

**定義**: 会議の目的からの逸脱度合いを評価する。

**スコア基準**:
- **低(1-3)**: 目的に沿う内容
- **中(4-6)**: 一部関連するが焦点がぼやける
- **高(7-9)**: 無関係・進行妨害

**評価時の質問**: この発言は会議の目的に直接関係しているか？

### 発言無効度

**定義**: 発言が目的達成・理解深化・合意形成にどれだけ寄与していないか（無効さ）を評価する。

**スコア基準**:
- **低(1-3)**: 無効度が低い（＝高い有効性）。目的達成に明確に寄与し、理解や共通理解の形成に貢献
- **中(4-6)**: 一部に無効さが見られる。部分的には目的達成に寄与するが、目的との結びつきや反映が不十分
- **高(7-9)**: 無効度が高い。目的達成や共通理解の形成にほとんど寄与せず、会議を停滞させる

**評価時の質問**: この発言はどの程度「無効」か？会議目的の達成や共通理解の形成を妨げていないか？

### 偏り度

**定義**: 討議の手続的公正（発言機会の平等・代表性・倫理性など）に対する偏り。

**スコア基準**:
- **低(1-3)**: 偏り抑制が保たれている
- **中(4-6)**: 一部の偏りが見られる
- **高(7-9)**: 独占・抑制・代表性欠如

**評価時の質問**: このやり取りは私的バイアスに強く引っ張られていないか？

### カスタム指標の追加

`extra.json`ファイルを編集することで、カスタム指標を追加できます：

```json
{
  "カスタム指標名": {
    "定義": "指標の定義を記述",
    "スコア基準": {
      "低(1-3)": "低スコアの説明",
      "中(4-6)": "中スコアの説明",
      "高(7-9)": "高スコアの説明"
    },
    "質問": "評価時に考慮する質問"
  }
}
```

## ファイル構成

```
well-meeting/
├── control.py              # メインコントロールサーバ
├── mic_api.py              # 音声入力と文字起こし
├── dash_server.py          # 可視化サーバ
├── my_node.py              # Nodeクラス（通信基盤）
├── extra.json              # 指標定義ファイル
├── prompt_template1.json   # LLMカット用プロンプトテンプレート
├── requirements.txt        # 依存パッケージ一覧
├── README.md               # このファイル
├── .env                    # 環境変数設定（作成が必要）
├── meeting_keeper.csv      # 発言データとスコア（自動生成）
├── log/                    # ログディレクトリ（自動生成）
│   ├── mic_text_*.txt      # 文字起こしログ
│   └── *_*.wav             # 音声ファイル
└── llmcut/                 # LLMカット実装
    ├── __init__.py
    └── core.py             # LLMカットコア実装
```

### 主要ファイルの説明

- **control.py**: 
  - TCPサーバーでmic_api.pyからのテキストを受信
  - LLMカットを使用して各指標を評価
  - FastAPIでデータを提供
  - CSVファイルに結果を保存

- **mic_api.py**:
  - マイクから音声を取得
  - VADで音声検出
  - OpenAI Whisper APIで文字起こし
  - control.pyへTCP通信で送信

- **dash_server.py**:
  - control.pyのFastAPIからデータを取得
  - Plotlyでグラフとテーブルを生成
  - 5秒間隔で自動更新

- **extra.json**:
  - 指標の定義、スコア基準、評価時の質問を定義

- **prompt_template1.json**:
  - LLMカットで使用するプロンプトテンプレート

## トラブルシューティング

### ポートが使用中

**エラー**: `Address already in use` またはポートが使用中

**解決方法**:
1. 使用中のポートを確認:
```bash
lsof -i:50000  # CONTROL_PORTの場合
```

2. プロセスを停止するか、`.env`でポート番号を変更

### OpenAI APIキーエラー

**エラー**: `OPENAI_API_KEY が設定されていません`

**解決方法**:
1. `.env`ファイルに`OPENAI_API_KEY`を設定
2. ファイルのパスが正しいか確認（`--file`オプション使用時）

### マイクが検出されない

**エラー**: 音声が検出されない

**解決方法**:
1. システムのマイク権限を確認（macOS: システム環境設定 > セキュリティとプライバシー）
2. マイクデバイスが正しく接続されているか確認
3. `sounddevice`で利用可能なデバイスを確認:
```python
import sounddevice as sd
print(sd.query_devices())
```

### 文字起こしが失敗する

**エラー**: 文字起こし結果が空

**解決方法**:
1. 音声が十分な長さ（0.8秒以上）か確認
2. 音声の品質を確認（ノイズが多い場合はフィルタが適用されます）
3. OpenAI APIの利用制限を確認

### ダッシュボードが更新されない

**エラー**: ダッシュボードにデータが表示されない

**解決方法**:
1. control.pyが正常に起動しているか確認
2. APIエンドポイントにアクセスできるか確認:
```bash
curl http://localhost:8008/health
curl http://localhost:8008/data
```
3. ブラウザのコンソールでエラーを確認

### LLMカットの評価が失敗する

**エラー**: スコアリングが失敗する

**解決方法**:
1. OpenAI APIキーが正しいか確認
2. モデル名が正しいか確認（`OPENAI_MODEL_NAME`）
3. APIの利用制限を確認
4. `prompt_template1.json`が正しく読み込まれているか確認

## 開発者向け情報

### アーキテクチャの詳細

#### LLMカットの仕組み

LLMカットは、OpenAI APIの`logprobs`機能を使用して、各スコア（1-9）の確率を取得し、以下の方法で確信度を計算します：

1. 各スコア（1-9）の対数確率を取得
2. 最大確率のスコアを選択
3. 最大確率と2番目に大きい確率の差を確信度として計算

```python
# llmcut/core.py の実装
diff = -df[prob_target].apply(np.exp).apply(lambda x: x.nlargest(2).diff().iloc[-1], axis=1)
conf = abs(diff)
```

#### データフロー

1. **音声入力** (mic_api.py)
   - マイク → VAD検出 → 音声バッファ → Whisper API → テキスト

2. **評価処理** (control.py)
   - テキスト受信 → プロンプト生成 → LLMカット並列評価 → スコア取得 → CSV保存

3. **可視化** (dash_server.py)
   - APIからデータ取得 → DataFrame変換 → Plotlyグラフ生成 → ブラウザ表示

### カスタマイズ方法

#### 指標の追加

`extra.json`に新しい指標を追加し、`.env`の`SELECTED_METRICS`に追加します。

#### プロンプトのカスタマイズ

`prompt_template1.json`を編集することで、LLMへのプロンプトをカスタマイズできます。

#### 評価行数の変更

`.env`の`EVAL_LINES`を変更することで、評価時に考慮する過去の発言数を変更できます。

### パフォーマンス最適化

- **並列評価**: 複数の指標は並列で評価されるため、処理時間は指標数に依存しません
- **バッファリング**: 音声はバッファに蓄積され、VADで検出された時点で処理されます
- **非同期処理**: FastAPIは非同期で動作し、複数のリクエストを同時に処理できます

### ログとデバッグ

- **音声ログ**: `log/`ディレクトリに音声ファイル（WAV形式）が保存されます
- **テキストログ**: `log/mic_text_*.txt`に文字起こし結果が保存されます
- **CSVデータ**: `meeting_keeper.csv`にすべての発言とスコアが保存されます

### テスト方法

基本的な動作確認:

```bash
# 1. 構文チェック
python -m py_compile control.py mic_api.py dash_server.py

# 2. モジュールインポート確認
python -c "import control; import mic_api; import dash_server"

# 3. パラメータ初期化確認
python -c "from control import init_params; print(init_params('.env'))"
```

## ライセンス

このプロジェクトのライセンス情報は、プロジェクトのルートディレクトリを確認してください。

## サポート

問題が発生した場合は、以下を確認してください：

1. すべての依存パッケージがインストールされているか
2. `.env`ファイルが正しく設定されているか
3. ポートが使用可能か
4. OpenAI APIキーが有効か

詳細なエラーメッセージは、各サーバーのターミナル出力を確認してください。
