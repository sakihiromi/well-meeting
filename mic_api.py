# mic_api.py
# VADã§éŸ³å£°ã®åˆ‡ã‚Œç›®ã‚’æ¤œå‡ºâ†’OpenAI Whisperã§ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›â†’control.pyã¸é€ä¿¡
import socket
import sounddevice as sd
import numpy as np
import webrtcvad
import time
from scipy.signal import butter, lfilter
import wave
import datetime
import unicodedata
import threading
import os
from dotenv import load_dotenv
import json
import socketserver
from threading import Lock
import sys
import tempfile
import traceback
from openai import OpenAI

# å®Ÿè¡Œæ™‚åˆ»ã®ãƒ•ã‚¡ã‚¤ãƒ«å
this_time = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
outputfile = f"./log/mic_text_{this_time}.txt"

# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ï¼ˆTTSãƒ¡ãƒ¼ã‚¿ï¼‰
playback_rms = 0.0    # 0..1
last_meter_ts = 0.0   # æœ€çµ‚å—ä¿¡æ™‚åˆ»
_state_lock = Lock()

# VADè¨­å®š
vad = webrtcvad.Vad(0)  # 0~3ï¼ˆæ„Ÿåº¦ï¼‰é«˜ã„ã»ã©ç„¡éŸ³ã‚’æ¤œå‡ºã—ã‚„ã™ã„
samplerate = 16000
frame_duration = 30  # ms
frame_size = int(samplerate * frame_duration / 1000)
min_duration = 0.8  # ç§’
min_bytes = int(samplerate * min_duration * 2)  # 2ãƒã‚¤ãƒˆ = int16

# èª¤ä½œå‹•é˜²æ­¢ã®ãŸã‚ã®è¨­å®š
MIN_TEXT_LENGTH = 5  # æœ€å°ãƒ†ã‚­ã‚¹ãƒˆé•·ï¼ˆæ–‡å­—æ•°ï¼‰- æ„å‘³ã®ã‚ã‚‹ç™ºè¨€ã®ãŸã‚å¼•ãä¸Šã’
MAX_TEXT_LENGTH = 500  # æœ€å¤§ãƒ†ã‚­ã‚¹ãƒˆé•·ï¼ˆæ–‡å­—æ•°ï¼‰
SILENCE_THRESHOLD = 0.3  # ç„¡éŸ³æ¤œå‡ºã®é–¾å€¤ï¼ˆç§’ï¼‰
SILENCE_GRACE_PERIOD = 1.5  # ç„¡éŸ³æ¤œå‡ºã®çŒ¶äºˆæœŸé–“ï¼ˆç§’ï¼‰- ç™ºè¨€é€”ä¸­ã®é–“ã‚’è¨±å®¹

def init_params(file_path):
    load_dotenv(file_path)
    return {
        "control_port": int(os.getenv("CONTROL_PORT", 50000)),
        "mic_port": int(os.getenv("MIC_PORT", 50001)),
        "openai_api_key": os.getenv("OPENAI_API_KEY", ""),
        "filter_model": os.getenv("FILTER_MODEL", "gpt-4o-mini"),
        "filter_confidence_threshold": float(os.getenv("FILTER_CONFIDENCE_THRESHOLD", "0.6")),
        "enable_llm_filter": os.getenv("ENABLE_LLM_FILTER", "true").lower() == "true",
    }

def hankaku_to_zenkaku(text):
    new_text = ''
    for c in text:
        if unicodedata.east_asian_width(c) in ('Na', 'H'):
            try:
                new_text += unicodedata.normalize('NFKC', c)
            except:
                new_text += c
        else:
            new_text += c
    return new_text

def sanitize_filename(text):
    text = text.replace(" ", "ã€€")
    for ch, zch in zip(r'\/:*?"<>|', "ï¿¥ï¼ï¼šï¼Šï¼Ÿï¼œï¼ï½œ"):
        text = text.replace(ch, zch)
    text = hankaku_to_zenkaku(text)
    return text

def save_wav(filename, audio_bytes, samplerate=16000):
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    with wave.open(filename, "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)  # 16bit PCM
        wf.setframerate(samplerate)
        wf.writeframes(audio_bytes)

wav_set = 0

def bandpass_filter(audio, sr=16000, lowcut=200, highcut=4000):
    b, a = butter(2, [lowcut/(sr/2), highcut/(sr/2)], btype='band')
    return lfilter(b, a, audio)

def set_filter(audio):
    # â‘  ãƒã‚¤ãƒˆåˆ—â†’int16â†’float32
    np_audio = np.frombuffer(audio, dtype=np.int16).astype(np.float32)
    # â‘¡ ãƒ•ã‚£ãƒ«ã‚¿
    np_audio = bandpass_filter(np_audio, sr=samplerate)
    # â‘¢ int16ã«æˆ»ã™ï¼ˆã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã‚‚æ¨å¥¨ï¼‰
    np_audio = np.clip(np_audio, -32768, 32767).astype(np.int16)
    # â‘£ bytesåŒ–
    return np_audio.tobytes()

def text_output(text):
    global outputfile
    os.makedirs(os.path.dirname(outputfile), exist_ok=True)
    with open(outputfile, "a", encoding="utf-8") as f:
        f.write(text + "\n")
    print(text)

def is_speech(frame_bytes):
    return vad.is_speech(frame_bytes, samplerate)

def output(duration, speech_time, text, data):
    global wav_set, this_time
    print(f"éŒ²éŸ³æ™‚é–“: {duration:.2f}")
    print(f"ç™ºè©±æ™‚é–“: {speech_time}")
    print(f"ä¿¡é ¼æ€§: {speech_time / duration:.2f}")
    out_text = f"{wav_set}_{text}"
    wav_set += 1
    text_output(out_text)
    save_wav(f"./log/{this_time}_{out_text}.wav", data)

# TTSã‹ã‚‰ã®é€šçŸ¥ã‚’å—ã‘ã‚‹è»½é‡ã‚µãƒ¼ãƒ
class ControlHandler(socketserver.BaseRequestHandler):
    def handle(self):
        global playback_rms, last_meter_ts
        try:
            data = self.request.recv(4096)
            msg = json.loads(data.decode("utf-8"))
        except Exception:
            return
        if "meter" in msg:
            with _state_lock:
                playback_rms = float(msg["meter"])
                last_meter_ts = time.time()

def start_control_server(port: int):
    srv = socketserver.TCPServer(("0.0.0.0", port), ControlHandler)
    t = threading.Thread(target=srv.serve_forever, daemon=True)
    t.start()
    print(f"[mic] control server listening on {port}")

# OpenAI Whisperã§æ–‡å­—èµ·ã“ã—
def transcribe_with_openai(audio_bytes, params, sr=16000):
    """
    16kHz/mono/PCM16ã®WAVãƒã‚¤ãƒˆåˆ—ã‚’OpenAIã®gpt-4o-mini-transcribeã§æ–‡å­—èµ·ã“ã—ã€‚
    å¤±æ•—æ™‚ã¯ç©ºæ–‡å­—ã‚’è¿”ã™ã€‚
    """
    api_key = params.get("openai_api_key", "")
    if not api_key:
        print("ERROR: OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆ.envã«è¿½è¨˜ã—ã¦ãã ã•ã„ï¼‰")
        return ""

    client = OpenAI(api_key=api_key)

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«WAVã¨ã—ã¦ä¿å­˜
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    try:
        with wave.open(tmp.name, "wb") as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)  # 16bit PCM
            wf.setframerate(sr)
            wf.writeframes(audio_bytes)

        with open(tmp.name, "rb") as f:
            resp = client.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=f,
                language="ja",
            )
        text = getattr(resp, "text", "") or ""
        return text.strip()
    except Exception as e:
        print("OpenAI STT error:", e)
        traceback.print_exc()
        return ""
    finally:
        try:
            os.unlink(tmp.name)
        except Exception:
            pass

def is_complete_sentence(text):
    """
    æ©Ÿæ¢°çš„ã«æ–‡ãŒå®Œçµã—ã¦ã„ã‚‹ã‹ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹
    å¥èª­ç‚¹ã‚„çµ‚åŠ©è©ã®å­˜åœ¨ã‚’ç¢ºèª
    """
    if not text:
        return False
    
    # å¥èª­ç‚¹ãƒã‚§ãƒƒã‚¯
    if text.endswith(("ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?")):
        return True
    
    # çµ‚åŠ©è©ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ˆãã‚ã‚‹çµ‚åŠ©è©ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    ending_patterns = [
        "ã§ã™", "ã¾ã™", "ã¾ã—ãŸ", "ã§ã—ãŸ",
        "ã­", "ã‚ˆ", "ãª", "ã‹", "ã‚",
        "ã ã­", "ã ã‚ˆ", "ã ãª", "ã ã‚",
        "ã§ã™ã­", "ã§ã™ã‚ˆ", "ã¾ã™ã­", "ã¾ã™ã‚ˆ",
        "ã¾ã›ã‚“", "ã¾ã›ã‚“ã§ã—ãŸ",
        "ãã ã•ã„", "ã¾ã—ã‚‡ã†", "ã§ã—ã‚‡ã†",
    ]
    
    for pattern in ending_patterns:
        if text.endswith(pattern):
            return True
    
    return False

def check_utterance_completeness_llm(text, params):
    """
    GPT-4o-miniã‚’ä½¿ã£ã¦ç™ºè¨€ã®å®Œå…¨æ€§ã‚’åˆ¤å®šã™ã‚‹
    
    æˆ»ã‚Šå€¤:
        dict: {
            "is_complete": bool,  # å®Œå…¨ãªç™ºè¨€ã‹ã©ã†ã‹
            "confidence": float,  # ç¢ºä¿¡åº¦ (0.0-1.0)
            "reason": str        # åˆ¤å®šç†ç”±
        }
    """
    api_key = params.get("openai_api_key", "")
    if not api_key:
        print("WARNING: OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚LLMãƒ•ã‚£ãƒ«ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return {"is_complete": True, "confidence": 0.0, "reason": "API key not set"}
    
    if not params.get("enable_llm_filter", True):
        print("LLMãƒ•ã‚£ãƒ«ã‚¿ãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚")
        return {"is_complete": True, "confidence": 1.0, "reason": "LLM filter disabled"}
    
    client = OpenAI(api_key=api_key)
    model = params.get("filter_model", "gpt-4o-mini")
    
    prompt = f"""ä»¥ä¸‹ã®ç™ºè¨€ãŒå®Œå…¨ãªæ–‡ã‹ã€é€”ä¸­ã§åˆ‡ã‚Œã¦ã„ã‚‹ä¸å®Œå…¨ãªæ–‡ã‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

åˆ¤å®šåŸºæº–:
- å®Œå…¨: æ–‡ã¨ã—ã¦æ„å‘³ãŒå®Œçµã—ã¦ã„ã‚‹ã€ä¸»èªãƒ»è¿°èªãŒæƒã£ã¦ã„ã‚‹ã€æ–‡æœ«ãŒé©åˆ‡
- ä¸å®Œå…¨: æ–‡ãŒé€”ä¸­ã§çµ‚ã‚ã£ã¦ã„ã‚‹ã€ä¸»èªã‚„è¿°èªãŒæ¬ ã‘ã¦ã„ã‚‹ã€ãƒ•ã‚£ãƒ©ãƒ¼ã®ã¿

ç™ºè¨€: "{text}"

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{{
  "is_complete": true ã¾ãŸã¯ false,
  "confidence": 0.0ã‹ã‚‰1.0ã®æ•°å€¤,
  "reason": "åˆ¤å®šç†ç”±ã‚’ç°¡æ½”ã«"
}}
"""
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯æ—¥æœ¬èªã®æ–‡ã®å®Œå…¨æ€§ã‚’åˆ¤å®šã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0,
            max_tokens=100,
            response_format={"type": "json_object"},
        )
        
        result_text = response.choices[0].message.content
        result = json.loads(result_text)
        
        print(f"[LLMãƒ•ã‚£ãƒ«ã‚¿] ç™ºè¨€: '{text[:30]}...' -> å®Œå…¨æ€§: {result.get('is_complete')}, ç¢ºä¿¡åº¦: {result.get('confidence'):.2f}")
        return result
        
    except Exception as e:
        print(f"LLMãƒ•ã‚£ãƒ«ã‚¿ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãªã„ï¼ˆç™ºè¨€ã‚’é€šã™ï¼‰
        return {"is_complete": True, "confidence": 0.0, "reason": f"Error: {str(e)}"}

def should_filter_text(text, params):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã¹ãã‹ã‚’åˆ¤å®šã™ã‚‹
    
    æ®µéšçš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°:
    1. æ©Ÿæ¢°çš„ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆé«˜é€Ÿï¼‰
    2. LLMãƒ•ã‚£ãƒ«ã‚¿ï¼ˆç²¾å¯†ï¼‰
    
    æˆ»ã‚Šå€¤:
        tuple: (should_filter: bool, reason: str)
        - should_filter: Trueãªã‚‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆç ´æ£„ï¼‰
        - reason: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç†ç”±
    """
    # ã‚¹ãƒ†ãƒ¼ã‚¸1: æ©Ÿæ¢°çš„ãƒ•ã‚£ãƒ«ã‚¿
    if len(text) < MIN_TEXT_LENGTH:
        return True, f"ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã™ãã¾ã™ï¼ˆ{len(text)}æ–‡å­— < {MIN_TEXT_LENGTH}æ–‡å­—ï¼‰"
    
    if len(text) > MAX_TEXT_LENGTH:
        # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚ã‚‹ãŒã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¯ã—ãªã„
        print(f"ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã¾ã™ï¼ˆ{len(text)}æ–‡å­— > {MAX_TEXT_LENGTH}æ–‡å­—ï¼‰ã€‚åˆ‡ã‚Šè©°ã‚ã¾ã™ã€‚")
        return False, "OK (truncated)"
    
    # ã¾ãšæ©Ÿæ¢°çš„ã«å®Œå…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯
    if is_complete_sentence(text):
        print(f"[æ©Ÿæ¢°çš„ãƒ•ã‚£ãƒ«ã‚¿] å®Œå…¨ãªæ–‡ã¨åˆ¤å®š: '{text[:30]}...'")
        return False, "OK (mechanically complete)"
    
    # ã‚¹ãƒ†ãƒ¼ã‚¸2: LLMãƒ•ã‚£ãƒ«ã‚¿ï¼ˆæ©Ÿæ¢°çš„ãƒ•ã‚£ãƒ«ã‚¿ã§ä¸å®Œå…¨ã¨åˆ¤å®šã•ã‚ŒãŸå ´åˆã®ã¿ï¼‰
    if params.get("enable_llm_filter", True):
        llm_result = check_utterance_completeness_llm(text, params)
        is_complete = llm_result.get("is_complete", True)
        confidence = llm_result.get("confidence", 0.0)
        reason = llm_result.get("reason", "")
        
        threshold = params.get("filter_confidence_threshold", 0.6)
        
        # ç¢ºä¿¡åº¦ãŒé–¾å€¤ä»¥ä¸Šã®å ´åˆã®ã¿LLMã®åˆ¤å®šã‚’ä¿¡é ¼
        if confidence >= threshold:
            if not is_complete:
                return True, f"LLMãƒ•ã‚£ãƒ«ã‚¿: ä¸å®Œå…¨ãªç™ºè¨€ï¼ˆç¢ºä¿¡åº¦: {confidence:.2f}, ç†ç”±: {reason}ï¼‰"
            else:
                return False, f"LLMãƒ•ã‚£ãƒ«ã‚¿: å®Œå…¨ãªç™ºè¨€ï¼ˆç¢ºä¿¡åº¦: {confidence:.2f}ï¼‰"
        else:
            # ç¢ºä¿¡åº¦ãŒä½ã„å ´åˆã¯é€šã™ï¼ˆå½é™½æ€§ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
            print(f"[LLMãƒ•ã‚£ãƒ«ã‚¿] ç¢ºä¿¡åº¦ãŒä½ã„ãŸã‚é€šã—ã¾ã™ï¼ˆ{confidence:.2f} < {threshold}ï¼‰")
            return False, f"OK (low confidence: {confidence:.2f})"
    
    # LLMãƒ•ã‚£ãƒ«ã‚¿ãŒç„¡åŠ¹ã€ã¾ãŸã¯æ©Ÿæ¢°çš„ãƒ•ã‚£ãƒ«ã‚¿ã§åˆ¤å®šã§ããªã‹ã£ãŸå ´åˆã¯é€šã™
    print(f"[ãƒ•ã‚£ãƒ«ã‚¿] åˆ¤å®šä¸èƒ½ã®ãŸã‚é€šã—ã¾ã™: '{text[:30]}...'")
    return False, "OK (uncertain)"

def send_audio(full_data, params):
    """
    éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’OpenAI Whisperã§æ–‡å­—èµ·ã“ã—ã—ã¦control.pyã¸é€ä¿¡
    æ®µéšçš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ©Ÿæ¢°çš„ â†’ LLMï¼‰ã§ä¸å®Œå…¨ãªç™ºè¨€ã‚’é™¤å¤–
    """
    global samplerate

    data = set_filter(full_data)
    duration = len(full_data) / samplerate / 2.0

    # èª¤ä½œå‹•é˜²æ­¢: çŸ­ã™ãã‚‹éŸ³å£°ã¯ã‚¹ã‚­ãƒƒãƒ—
    if duration < min_duration:
        print(f"éŸ³å£°ãŒçŸ­ã™ãã¾ã™ï¼ˆ{duration:.2f}ç§’ < {min_duration}ç§’ï¼‰ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return 0.0, "", duration

    # OpenAIã§æ–‡å­—èµ·ã“ã—
    text = transcribe_with_openai(data, params, sr=samplerate)

    # èª¤ä½œå‹•é˜²æ­¢: ãƒ†ã‚­ã‚¹ãƒˆã®æ¤œè¨¼
    if not text:
        print("æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã§ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return 0.0, "", duration

    # æ®µéšçš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ©Ÿæ¢°çš„ + LLMï¼‰
    should_filter, filter_reason = should_filter_text(text, params)
    if should_filter:
        print(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: {filter_reason}")
        return 0.0, "", duration
    
    # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
    if len(text) > MAX_TEXT_LENGTH:
        text = text[:MAX_TEXT_LENGTH]

    s_text = sanitize_filename(text)
    conf = 1.0  # OpenAI Whisperã¯ä¿¡é ¼æ€§ãŒé«˜ã„ãŸã‚1.0
    s_time = duration

    output(duration, s_time, s_text, full_data)
    print(f"[ãƒ•ã‚£ãƒ«ã‚¿é€šé] '{text[:50]}...' (ç†ç”±: {filter_reason})")
    return conf, s_text, duration

def start_client(ip, port, message):
    """control.pyã¸ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡"""
    try:
        print(f"start_client: {message}\tport:{port}")
        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        client_socket.connect((ip, port))
        message = json.dumps(message, ensure_ascii=False)
        client_socket.send(message.encode("utf-8"))
        client_socket.close()
    except Exception as e:
        print(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()

def record(params):
    """ãƒ¡ã‚¤ãƒ³éŒ²éŸ³ãƒ«ãƒ¼ãƒ—: VADã§éŸ³å£°æ¤œå‡ºâ†’Whisperã§æ–‡å­—èµ·ã“ã—â†’control.pyã¸é€ä¿¡"""
    was_speaking = False
    notified_speaking = False  # speaking:Trueé€šçŸ¥ã‚’é€ã£ãŸã‹ã©ã†ã‹
    print("ğŸ™ï¸ Listening ...")
    
    with sd.RawInputStream(samplerate=samplerate, channels=1, dtype="int16", blocksize=frame_size) as stream:
        all_buffer = bytearray()

        while True:
            frame, _ = stream.read(frame_size)
            is_speaking = is_speech(frame)
            
            # è‡ªå·±ä¸€è‡´ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚¨ã‚³ãƒ¼é˜²æ­¢ï¼‰
            mic_rms = float(np.sqrt(np.mean(np.frombuffer(frame, dtype=np.int16).astype(np.float32)**2)) / 32768.0)

            with _state_lock:
                prms = playback_rms
                age = time.time() - last_meter_ts
            meter_valid = (age < 0.3)  # ç›´è¿‘300msä»¥å†…ã®ãƒ¡ãƒ¼ã‚¿ã ã‘æœ‰åŠ¹

            leak_factor = 0.25  # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼æ¼ã‚Œã®æƒ³å®šå‰²åˆ
            offset = 0.005  # -46dBFSç›¸å½“ã®åº•ä¸Šã’
            if meter_valid:
                likely_echo = mic_rms <= (prms * leak_factor + offset)
            else:
                likely_echo = False

            if not likely_echo:
                if is_speaking:
                    all_buffer.extend(frame)
                    if not was_speaking:
                        # æœ€åˆã®éŸ³å£°æ¤œå‡ºæ™‚ã¯å³åº§ã«was_speakingã‚’Trueã«ã™ã‚‹
                        was_speaking = True
                        notified_speaking = False
                        print(f"[DEBUG] éŸ³å£°æ¤œå‡ºé–‹å§‹: buffer={len(all_buffer)}ãƒã‚¤ãƒˆ, min={min_bytes}ãƒã‚¤ãƒˆ")
                    # min_bytesã«é”ã—ãŸã‚‰é€šçŸ¥ã‚’é€ã‚‹ï¼ˆ1å›ã ã‘ï¼‰
                    if len(all_buffer) >= min_bytes and was_speaking and not notified_speaking:
                        print(f"speaking:True")
                        start_client("localhost", params["control_port"], {"speaking": "Yes"})
                        notified_speaking = True
                else:
                    if was_speaking:
                        # éŸ³å£°ãŒçµ‚äº†ã—ãŸæ™‚ã€min_bytesä»¥ä¸Šãªã‚‰å‡¦ç†ã™ã‚‹
                        if len(all_buffer) >= min_bytes:
                            was_speaking = False
                            notified_speaking = False
                            conf, text, duration = send_audio(all_buffer, params)
                            if conf > 0.0 and text:
                                print(f"user:{text}")
                                # control.pyã¸ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡
                                start_client("localhost", params["control_port"], {
                                    "user": "",
                                    "text": text,
                                    "speaking": "No"
                                })
                            else:
                                print(f"speaking:False (æ–‡å­—èµ·ã“ã—å¤±æ•—)")
                                start_client("localhost", params["control_port"], {"speaking": "Error"})
                        else:
                            # çŸ­ã™ãã‚‹éŸ³å£°ã¯ã‚¹ã‚­ãƒƒãƒ—
                            print(f"éŸ³å£°ãŒçŸ­ã™ãã¾ã™ï¼ˆ{len(all_buffer)}ãƒã‚¤ãƒˆ < {min_bytes}ãƒã‚¤ãƒˆï¼‰ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            was_speaking = False
                            notified_speaking = False
                    all_buffer.clear()

if __name__ == "__main__":
    if "--file" in sys.argv:
        params_file = sys.argv[sys.argv.index("--file") + 1]
    else:
        params_file = ".env"
    
    params = init_params(params_file)

    # ãƒ­ã‚°æ ¼ç´å…ˆã®ç”¨æ„
    os.makedirs("./log", exist_ok=True)

    socket_thread = threading.Thread(target=record, args=(params,), daemon=True)
    socket_thread.start()
    start_control_server(int(params.get("mic_port", 5001)))

    while True:
        try:
            time.sleep(1)
        except KeyboardInterrupt:
            print("Bye.")
            break

