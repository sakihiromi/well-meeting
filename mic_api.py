# mic_api.py
# VADã§éŸ³å£°ã®åˆ‡ã‚Œç›®ã‚’æ¤œå‡ºâ†’OpenAI Whisperã§ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›â†’control.pyã¸é€ä¿¡
import socket
import sounddevice as sd
import numpy as np
import webrtcvad
import time
from scipy.signal import butter, lfilter
import wave
import datetime
import unicodedata
import threading
import os
from dotenv import load_dotenv
import json
import socketserver
from threading import Lock
import sys
import tempfile
import traceback
from openai import OpenAI

# å®Ÿè¡Œæ™‚åˆ»ã®ãƒ•ã‚¡ã‚¤ãƒ«å
this_time = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
outputfile = f"./log/mic_text_{this_time}.txt"

# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ï¼ˆTTSãƒ¡ãƒ¼ã‚¿ï¼‰
playback_rms = 0.0    # 0..1
last_meter_ts = 0.0   # æœ€çµ‚å—ä¿¡æ™‚åˆ»
_state_lock = Lock()

# VADè¨­å®š
vad = webrtcvad.Vad(0)  # 0~3ï¼ˆæ„Ÿåº¦ï¼‰é«˜ã„ã»ã©ç„¡éŸ³ã‚’æ¤œå‡ºã—ã‚„ã™ã„
samplerate = 16000
frame_duration = 30  # ms
frame_size = int(samplerate * frame_duration / 1000)
min_duration = 0.8  # ç§’
min_bytes = int(samplerate * min_duration * 2)  # 2ãƒã‚¤ãƒˆ = int16

# èª¤ä½œå‹•é˜²æ­¢ã®ãŸã‚ã®è¨­å®š
MIN_TEXT_LENGTH = 2  # æœ€å°ãƒ†ã‚­ã‚¹ãƒˆé•·ï¼ˆæ–‡å­—æ•°ï¼‰
MAX_TEXT_LENGTH = 500  # æœ€å¤§ãƒ†ã‚­ã‚¹ãƒˆé•·ï¼ˆæ–‡å­—æ•°ï¼‰
SILENCE_THRESHOLD = 0.3  # ç„¡éŸ³æ¤œå‡ºã®é–¾å€¤ï¼ˆç§’ï¼‰

def init_params(file_path):
    load_dotenv(file_path)
    return {
        "control_port": int(os.getenv("CONTROL_PORT", 50000)),
        "mic_port": int(os.getenv("MIC_PORT", 50001)),
        "openai_api_key": os.getenv("OPENAI_API_KEY", ""),
    }

def hankaku_to_zenkaku(text):
    new_text = ''
    for c in text:
        if unicodedata.east_asian_width(c) in ('Na', 'H'):
            try:
                new_text += unicodedata.normalize('NFKC', c)
            except:
                new_text += c
        else:
            new_text += c
    return new_text

def sanitize_filename(text):
    text = text.replace(" ", "ã€€")
    for ch, zch in zip(r'\/:*?"<>|', "ï¿¥ï¼ï¼šï¼Šï¼Ÿï¼œï¼ï½œ"):
        text = text.replace(ch, zch)
    text = hankaku_to_zenkaku(text)
    return text

def save_wav(filename, audio_bytes, samplerate=16000):
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    with wave.open(filename, "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)  # 16bit PCM
        wf.setframerate(samplerate)
        wf.writeframes(audio_bytes)

wav_set = 0

def bandpass_filter(audio, sr=16000, lowcut=200, highcut=4000):
    b, a = butter(2, [lowcut/(sr/2), highcut/(sr/2)], btype='band')
    return lfilter(b, a, audio)

def set_filter(audio):
    # â‘  ãƒã‚¤ãƒˆåˆ—â†’int16â†’float32
    np_audio = np.frombuffer(audio, dtype=np.int16).astype(np.float32)
    # â‘¡ ãƒ•ã‚£ãƒ«ã‚¿
    np_audio = bandpass_filter(np_audio, sr=samplerate)
    # â‘¢ int16ã«æˆ»ã™ï¼ˆã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã‚‚æ¨å¥¨ï¼‰
    np_audio = np.clip(np_audio, -32768, 32767).astype(np.int16)
    # â‘£ bytesåŒ–
    return np_audio.tobytes()

def text_output(text):
    global outputfile
    os.makedirs(os.path.dirname(outputfile), exist_ok=True)
    with open(outputfile, "a", encoding="utf-8") as f:
        f.write(text + "\n")
    print(text)

def is_speech(frame_bytes):
    return vad.is_speech(frame_bytes, samplerate)

def output(duration, speech_time, text, data):
    global wav_set, this_time
    print(f"éŒ²éŸ³æ™‚é–“: {duration:.2f}")
    print(f"ç™ºè©±æ™‚é–“: {speech_time}")
    print(f"ä¿¡é ¼æ€§: {speech_time / duration:.2f}")
    out_text = f"{wav_set}_{text}"
    wav_set += 1
    text_output(out_text)
    save_wav(f"./log/{this_time}_{out_text}.wav", data)

# TTSã‹ã‚‰ã®é€šçŸ¥ã‚’å—ã‘ã‚‹è»½é‡ã‚µãƒ¼ãƒ
class ControlHandler(socketserver.BaseRequestHandler):
    def handle(self):
        global playback_rms, last_meter_ts
        try:
            data = self.request.recv(4096)
            msg = json.loads(data.decode("utf-8"))
        except Exception:
            return
        if "meter" in msg:
            with _state_lock:
                playback_rms = float(msg["meter"])
                last_meter_ts = time.time()

def start_control_server(port: int):
    srv = socketserver.TCPServer(("0.0.0.0", port), ControlHandler)
    t = threading.Thread(target=srv.serve_forever, daemon=True)
    t.start()
    print(f"[mic] control server listening on {port}")

# OpenAI Whisperã§æ–‡å­—èµ·ã“ã—
def transcribe_with_openai(audio_bytes, params, sr=16000):
    """
    16kHz/mono/PCM16ã®WAVãƒã‚¤ãƒˆåˆ—ã‚’OpenAIã®gpt-4o-mini-transcribeã§æ–‡å­—èµ·ã“ã—ã€‚
    å¤±æ•—æ™‚ã¯ç©ºæ–‡å­—ã‚’è¿”ã™ã€‚
    """
    api_key = params.get("openai_api_key", "")
    if not api_key:
        print("ERROR: OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆ.envã«è¿½è¨˜ã—ã¦ãã ã•ã„ï¼‰")
        return ""

    client = OpenAI(api_key=api_key)

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«WAVã¨ã—ã¦ä¿å­˜
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    try:
        with wave.open(tmp.name, "wb") as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)  # 16bit PCM
            wf.setframerate(sr)
            wf.writeframes(audio_bytes)

        with open(tmp.name, "rb") as f:
            resp = client.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=f,
                language="ja",
            )
        text = getattr(resp, "text", "") or ""
        return text.strip()
    except Exception as e:
        print("OpenAI STT error:", e)
        traceback.print_exc()
        return ""
    finally:
        try:
            os.unlink(tmp.name)
        except Exception:
            pass

def send_audio(full_data, params):
    """
    éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’OpenAI Whisperã§æ–‡å­—èµ·ã“ã—ã—ã¦control.pyã¸é€ä¿¡
    èª¤ä½œå‹•é˜²æ­¢ã®ãŸã‚ã®æ¤œè¨¼ã‚‚è¡Œã†
    """
    global samplerate

    data = set_filter(full_data)
    duration = len(full_data) / samplerate / 2.0

    # èª¤ä½œå‹•é˜²æ­¢: çŸ­ã™ãã‚‹éŸ³å£°ã¯ã‚¹ã‚­ãƒƒãƒ—
    if duration < min_duration:
        print(f"éŸ³å£°ãŒçŸ­ã™ãã¾ã™ï¼ˆ{duration:.2f}ç§’ < {min_duration}ç§’ï¼‰ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return 0.0, "", duration

    # OpenAIã§æ–‡å­—èµ·ã“ã—
    text = transcribe_with_openai(data, params, sr=samplerate)

    # èª¤ä½œå‹•é˜²æ­¢: ãƒ†ã‚­ã‚¹ãƒˆã®æ¤œè¨¼
    if not text:
        print("æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã§ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return 0.0, "", duration

    if len(text) < MIN_TEXT_LENGTH:
        print(f"ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã™ãã¾ã™ï¼ˆ{len(text)}æ–‡å­— < {MIN_TEXT_LENGTH}æ–‡å­—ï¼‰ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return 0.0, "", duration

    if len(text) > MAX_TEXT_LENGTH:
        print(f"ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã¾ã™ï¼ˆ{len(text)}æ–‡å­— > {MAX_TEXT_LENGTH}æ–‡å­—ï¼‰ã€‚åˆ‡ã‚Šè©°ã‚ã¾ã™ã€‚")
        text = text[:MAX_TEXT_LENGTH]

    s_text = sanitize_filename(text)
    conf = 1.0  # OpenAI Whisperã¯ä¿¡é ¼æ€§ãŒé«˜ã„ãŸã‚1.0
    s_time = duration

    output(duration, s_time, s_text, full_data)
    return conf, s_text, duration

def start_client(ip, port, message):
    """control.pyã¸ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡"""
    try:
        print(f"start_client: {message}\tport:{port}")
        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        client_socket.connect((ip, port))
        message = json.dumps(message, ensure_ascii=False)
        client_socket.send(message.encode("utf-8"))
        client_socket.close()
    except Exception as e:
        print(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()

def record(params):
    """ãƒ¡ã‚¤ãƒ³éŒ²éŸ³ãƒ«ãƒ¼ãƒ—: VADã§éŸ³å£°æ¤œå‡ºâ†’Whisperã§æ–‡å­—èµ·ã“ã—â†’control.pyã¸é€ä¿¡"""
    was_speaking = False
    notified_speaking = False  # speaking:Trueé€šçŸ¥ã‚’é€ã£ãŸã‹ã©ã†ã‹
    print("ğŸ™ï¸ Listening ...")
    
    with sd.RawInputStream(samplerate=samplerate, channels=1, dtype="int16", blocksize=frame_size) as stream:
        all_buffer = bytearray()

        while True:
            frame, _ = stream.read(frame_size)
            is_speaking = is_speech(frame)
            
            # è‡ªå·±ä¸€è‡´ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚¨ã‚³ãƒ¼é˜²æ­¢ï¼‰
            mic_rms = float(np.sqrt(np.mean(np.frombuffer(frame, dtype=np.int16).astype(np.float32)**2)) / 32768.0)

            with _state_lock:
                prms = playback_rms
                age = time.time() - last_meter_ts
            meter_valid = (age < 0.3)  # ç›´è¿‘300msä»¥å†…ã®ãƒ¡ãƒ¼ã‚¿ã ã‘æœ‰åŠ¹

            leak_factor = 0.25  # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼æ¼ã‚Œã®æƒ³å®šå‰²åˆ
            offset = 0.005  # -46dBFSç›¸å½“ã®åº•ä¸Šã’
            if meter_valid:
                likely_echo = mic_rms <= (prms * leak_factor + offset)
            else:
                likely_echo = False

            if not likely_echo:
                if is_speaking:
                    all_buffer.extend(frame)
                    if not was_speaking:
                        # æœ€åˆã®éŸ³å£°æ¤œå‡ºæ™‚ã¯å³åº§ã«was_speakingã‚’Trueã«ã™ã‚‹
                        was_speaking = True
                        notified_speaking = False
                        print(f"[DEBUG] éŸ³å£°æ¤œå‡ºé–‹å§‹: buffer={len(all_buffer)}ãƒã‚¤ãƒˆ, min={min_bytes}ãƒã‚¤ãƒˆ")
                    # min_bytesã«é”ã—ãŸã‚‰é€šçŸ¥ã‚’é€ã‚‹ï¼ˆ1å›ã ã‘ï¼‰
                    if len(all_buffer) >= min_bytes and was_speaking and not notified_speaking:
                        print(f"speaking:True")
                        start_client("localhost", params["control_port"], {"speaking": "Yes"})
                        notified_speaking = True
                else:
                    if was_speaking:
                        # éŸ³å£°ãŒçµ‚äº†ã—ãŸæ™‚ã€min_bytesä»¥ä¸Šãªã‚‰å‡¦ç†ã™ã‚‹
                        if len(all_buffer) >= min_bytes:
                            was_speaking = False
                            notified_speaking = False
                            conf, text, duration = send_audio(all_buffer, params)
                            if conf > 0.0 and text:
                                print(f"user:{text}")
                                # control.pyã¸ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡
                                start_client("localhost", params["control_port"], {
                                    "user": "",
                                    "text": text,
                                    "speaking": "No"
                                })
                            else:
                                print(f"speaking:False (æ–‡å­—èµ·ã“ã—å¤±æ•—)")
                                start_client("localhost", params["control_port"], {"speaking": "Error"})
                        else:
                            # çŸ­ã™ãã‚‹éŸ³å£°ã¯ã‚¹ã‚­ãƒƒãƒ—
                            print(f"éŸ³å£°ãŒçŸ­ã™ãã¾ã™ï¼ˆ{len(all_buffer)}ãƒã‚¤ãƒˆ < {min_bytes}ãƒã‚¤ãƒˆï¼‰ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            was_speaking = False
                            notified_speaking = False
                    all_buffer.clear()

if __name__ == "__main__":
    if "--file" in sys.argv:
        params_file = sys.argv[sys.argv.index("--file") + 1]
    else:
        params_file = ".env"
    
    params = init_params(params_file)

    # ãƒ­ã‚°æ ¼ç´å…ˆã®ç”¨æ„
    os.makedirs("./log", exist_ok=True)

    socket_thread = threading.Thread(target=record, args=(params,), daemon=True)
    socket_thread.start()
    start_control_server(int(params.get("mic_port", 5001)))

    while True:
        try:
            time.sleep(1)
        except KeyboardInterrupt:
            print("Bye.")
            break

